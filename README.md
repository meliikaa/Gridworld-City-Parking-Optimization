# Gridworld-City-Parking-Optimization

Welcome to the **Gridworld City Parking Optimization** project! In this project, we aim to tackle the challenge of optimizing the city's street parking system using Dynamic Programming techniques. The city, renowned for its thriving technology industry, has seen a surge in grid-loving software engineers, leading to a strain on its existing fixed-rate street parking system. To address this issue and promote social welfare, the city council has devised a novel approach to pricing.

## Project Overview

Gridworld City, a bustling metropolis, is facing an increased demand for parking due to the influx of software engineers. The existing street parking system charges a fixed rate but struggles to meet this heightened demand. To address this, the city council has chosen to implement a new pricing strategy based on a Markov decision process (MDP). This MDP models parking demand and integrates a reward function that aligns with the city's welfare objectives.

## Objectives

The primary goal of this project is to determine optimal policies for the revised parking pricing scheme using Dynamic Programming. The city's preferences are centered around maximizing social welfare while ensuring the availability of at least one parking spot at all times.

## Key Concepts

### 1. Markov Decision Process (MDP)

The foundation of our approach lies in the MDP framework. This mathematical model helps us capture the stochastic nature of parking demand and the decision-making process involved in parking pricing.

### 2.Policy Evaluation and Policy Improvement.


The reward function serves as the guiding principle for our optimization. It reflects the city's preferences, which include incentivizing higher parking utilization while guaranteeing the availability of at least one empty spot.

### 3. Value and Policy Iteration and Bellman Equation.

Dynamic Programming techniques provide us with a systematic way to find optimal solutions to complex problems. We'll use methods like Policy Iteration and Value Iteration to iteratively refine our parking policy until convergence.

## Getting Started

To contribute to this project or understand the parking optimization process, follow these steps:

1. **Clone the Repository:** Start by cloning the project repository to your local machine.

2. **Explore the Code:** Dive into the codebase to understand how the MDP, reward function, and Dynamic Programming techniques are implemented.

3. **Run Simulations:** Experiment with different scenarios and parking demand patterns. Observe how the optimal policy changes based on the city's preferences.

4. **Modify and Contribute:** If you're up for a challenge, you can enhance the reward function, try alternative optimization algorithms, or contribute additional features.

## Conclusion

The Gridworld City Parking Optimization project presents a fascinating intersection of technology, economics, and urban planning. By applying Dynamic Programming to the city's parking problem, we aim to create an optimal policy that maximizes social welfare while accommodating the unique preferences of Gridworld City. Through our efforts, we strive to ensure efficient parking utilization and availability, contributing to the overall well-being of the city's residents and visitors.

## Credits 
All credit for this repository is attributed to the "Fundamentals of Reinforcement Learning" course offered by the University of Alberta on Coursera. I extend our sincere gratitude to the creators of this course for their effort in developing and offering such valuable educational content.
